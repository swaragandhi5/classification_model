{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Importing necessary libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "b53ScnBEGS2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import batch_normalization\n",
        "from keras.layers.activation import LeakyReLU, ReLU"
      ],
      "metadata": {
        "id": "1ylL89FJfRZ3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Loading the dataset**<br>\n",
        "To load the dataset from local machine to the Google colab, we need to inport drive and mount the data from drive to colab. "
      ],
      "metadata": {
        "id": "T2-GkRbNGaV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhon72OLC0M3",
        "outputId": "2be6e218-908c-4af2-cd2c-b1ae9e98e3ad"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Data')"
      ],
      "metadata": {
        "id": "KuMoowfRfh3N"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Preprocess the data**<br>\n",
        "Preprocessing the data by normalizing the pixel values and applying data augmentation techniques such as flipping, rotating, and zooming. This will help the model generalize better to new data.<br><br>\n",
        "**Performing train, test and validation split of the data. The data has only 300 images in total so I splitted the training and Validation split as 80% and 20% respectively and using the same dataset for testing. It might overfit the model as we have used the previous dataset but the dataset was very small.**"
      ],
      "metadata": {
        "id": "gd0flS_JGyLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory('./', target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
        "validation_generator = train_datagen.flow_from_directory('./', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='validation')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory('./', target_size=(64, 64), batch_size=32, class_mode='categorical', shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9BuYzhwfmMM",
        "outputId": "d212657f-f526-47b0-92ad-482be24a21c9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Creating the model<br>**\n",
        "This is a Convolution Neural Network model for classification. We have several convolution layer with relu as activation function, pooling layers and dense layers. <br>\n",
        "For pooling layers, we have used maxpooling. It helps to reduce dimentionality. "
      ],
      "metadata": {
        "id": "SOGt4W_AI5De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add convolutional and pooling layers\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output of the previous layer to feed into dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add dense layers with dropout\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwW6ze3LfwJo",
        "outputId": "aaaa2093-b28a-4b92-dd44-c98d689f11d5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,633,603\n",
            "Trainable params: 1,633,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Compilation of model**<br>"
      ],
      "metadata": {
        "id": "Vl4DRM3yJjI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1ynOAj6fy2_",
        "outputId": "946c41bd-fb12-4453-f628-96152e9103fb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.2508 - accuracy: 0.3233\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 1.0459 - accuracy: 0.4167\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.8663 - accuracy: 0.6100\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.6481 - accuracy: 0.7267\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.5839 - accuracy: 0.7600\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.4917 - accuracy: 0.8100\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.5258 - accuracy: 0.8100\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.4974 - accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.4237 - accuracy: 0.8333\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3448 - accuracy: 0.8867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluating model on test dataset**"
      ],
      "metadata": {
        "id": "82ZDGVdEJxjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print('Validation accuracy:', accuracy)\n",
        "print('Validation loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfc2vfuFhGlA",
        "outputId": "ca54d872-3b7d-4d28-cd39-7e165414043a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 18s 2s/step - loss: 0.1972 - accuracy: 0.9267\n",
            "Validation accuracy: 0.9266666769981384\n",
            "Validation loss: 0.19718053936958313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving model for resuing it. "
      ],
      "metadata": {
        "id": "BHgAmv77J8qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('CNN_model.h5')"
      ],
      "metadata": {
        "id": "61gnPceqF2Cc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}